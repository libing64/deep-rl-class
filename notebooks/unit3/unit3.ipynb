{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit3/unit3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7xBVPzoXxOg"
      },
      "source": [
        "# Unit 3: Deep Q-Learning with Atari Games üëæ using RL Baselines3 Zoo\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/thumbnail.jpg\" alt=\"Unit 3 Thumbnail\">\n",
        "\n",
        "In this notebook, **you'll train a Deep Q-Learning agent** playing Space Invaders using [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo), a training framework based on [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) that provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
        "\n",
        "We're using the [RL-Baselines-3 Zoo integration, a vanilla version of Deep Q-Learning](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) with no extensions such as Double-DQN, Dueling-DQN, and Prioritized Experience Replay.\n",
        "\n",
        "‚¨áÔ∏è Here is an example of what **you will achieve** ‚¨áÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9S713biXntc"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykJiGevCMVc5"
      },
      "source": [
        "### üéÆ Environments:\n",
        "\n",
        "- [SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)\n",
        "\n",
        "You can see the difference between Space Invaders versions here üëâ https://gymnasium.farama.org/environments/atari/space_invaders/#variants\n",
        "\n",
        "### üìö RL-Library:\n",
        "\n",
        "- [RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wciHGjrFYz9m"
      },
      "source": [
        "## Objectives of this notebook üèÜ\n",
        "At the end of the notebook, you will:\n",
        "- Be able to understand deeper **how RL Baselines3 Zoo works**.\n",
        "- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score üî•.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsnP0rjxMn1e"
      },
      "source": [
        "## This notebook is from Deep Reinforcement Learning Course\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw6fJHIAZd-J"
      },
      "source": [
        "In this free course, you will:\n",
        "\n",
        "- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n",
        "- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- ü§ñ Train **agents in unique environments**\n",
        "\n",
        "And more check üìö the syllabus üëâ https://simoninithomas.github.io/deep-rl-course\n",
        "\n",
        "Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n",
        "\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vgANIBBZg1p"
      },
      "source": [
        "## Prerequisites üèóÔ∏è\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "üî≤ üìö **[Study Deep Q-Learning by reading Unit 3](https://huggingface.co/deep-rl-course/unit3/introduction)**  ü§ó"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kszpGFaRVhq"
      },
      "source": [
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR0jZtYreSI5"
      },
      "source": [
        "# Let's train a Deep Q-Learning agent playing Atari' Space Invaders üëæ and upload it to the Hub.\n",
        "\n",
        "We strongly recommend students **to use Google Colab for the hands-on exercises instead of running them on their personal computers**.\n",
        "\n",
        "By using Google Colab, **you can focus on learning and experimenting without worrying about the technical aspects of setting up your environments**.\n",
        "\n",
        "To validate this hands-on for the certification process, you need to push your trained model to the Hub and **get a result of >= 200**.\n",
        "\n",
        "To find your result, go to the leaderboard and find your model, **the result = mean_reward - std of reward**\n",
        "\n",
        "For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc8BnyVEc3Ys"
      },
      "source": [
        "## An advice üí°\n",
        "It's better to run this colab in a copy on your Google Drive, so that **if it timeouts** you still have the saved notebook on your Google Drive and do not need to fill everything from scratch.\n",
        "\n",
        "To do that you can either do `Ctrl + S` or `File > Save a copy in Google Drive.`\n",
        "\n",
        "Also, we're going to **train it for 90 minutes with 1M timesteps**. By typing `!nvidia-smi` will tell you what GPU you're using.\n",
        "\n",
        "And if you want to train more such 10 million steps, this will take about 9 hours, potentially resulting in Colab timing out. In that case, I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4FVzaoM6fC"
      },
      "source": [
        "## Set the GPU üí™\n",
        "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV0NyFdQM9ZG"
      },
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_cVefO-aYg"
      },
      "source": [
        "# Install RL-Baselines3 Zoo and its dependencies üìö\n",
        "\n",
        "If you see `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed.` **this is normal and it's not a critical error** there's a conflict of version. But the packages we need are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S1A_E4z3awa_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
            "Collecting git+https://github.com/DLR-RM/rl-baselines3-zoo\n",
            "  Cloning https://github.com/DLR-RM/rl-baselines3-zoo to /tmp/pip-req-build-5amh84nq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/rl-baselines3-zoo /tmp/pip-req-build-5amh84nq\n",
            "  Resolved https://github.com/DLR-RM/rl-baselines3-zoo to commit d29756c456caadbbebc15c35893674abb2453e0d\n",
            "  Running command git submodule update --init --recursive -q\n",
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_MllY6Om1eI"
      },
      "outputs": [],
      "source": [
        "!apt-get install swig cmake ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S9mJiKg6SqC"
      },
      "source": [
        "To be able to use Atari games in Gymnasium we need to install atari package. And accept-rom-license to download the rom files (games files)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsRP-lX1_2fC"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTpYcVZVMzUI"
      },
      "source": [
        "## Create a virtual display üîΩ\n",
        "\n",
        "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n",
        "\n",
        "Hence the following cell will install the librairies and create and run a virtual screen üñ•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV6wjQ7Be7p5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BE5JWP5rQIKf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f32be51fc10>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iPgzluo9z-u"
      },
      "source": [
        "## Train our Deep Q-Learning Agent to Play Space Invaders üëæ\n",
        "\n",
        "To train an agent with RL-Baselines3-Zoo, we just need to do two things:\n",
        "\n",
        "1. Create a hyperparameter config file that will contain our training hyperparameters called `dqn.yml`.\n",
        "\n",
        "This is a template example:\n",
        "\n",
        "```\n",
        "SpaceInvadersNoFrameskip-v4:\n",
        "  env_wrapper:\n",
        "    - stable_baselines3.common.atari_wrappers.AtariWrapper\n",
        "  frame_stack: 4\n",
        "  policy: 'CnnPolicy'\n",
        "  n_timesteps: !!float 1e6\n",
        "  buffer_size: 100000\n",
        "  learning_rate: !!float 1e-4\n",
        "  batch_size: 32\n",
        "  learning_starts: 100000\n",
        "  target_update_interval: 1000\n",
        "  train_freq: 4\n",
        "  gradient_steps: 1\n",
        "  exploration_fraction: 0.1\n",
        "  exploration_final_eps: 0.01\n",
        "  # If True, you need to deactivate handle_timeout_termination\n",
        "  # in the replay_buffer_kwargs\n",
        "  optimize_memory_usage: False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VjblFSVDQOj"
      },
      "source": [
        "Here we see that:\n",
        "- We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale, stack 4 frames)\n",
        "- We use `CnnPolicy`, since we use Convolutional layers to process the frames\n",
        "- We train it for 10 million `n_timesteps`\n",
        "- Memory (Experience Replay) size is 100000, aka the amount of experience steps you saved to train again your agent with.\n",
        "\n",
        "üí° My advice is to **reduce the training timesteps to 1M,** which will take about 90 minutes on a P100. `!nvidia-smi` will tell you what GPU you're using. At 10 million steps, this will take about 9 hours, which could likely result in Colab timing out. I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qTkbWrkECOJ"
      },
      "source": [
        "In terms of hyperparameters optimization, my advice is to focus on these 3 hyperparameters:\n",
        "- `learning_rate`\n",
        "- `buffer_size (Experience Memory size)`\n",
        "- `batch_size`\n",
        "\n",
        "As a good practice, you need to **check the documentation to understand what each hyperparameters does**: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn8bRTHvERRL"
      },
      "source": [
        "2. We start the training and save the models on `logs` folder üìÅ\n",
        "\n",
        "- Define the algorithm after `--algo`, where we save the model after `-f` and where the hyperparameter config is after `-c`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Xr1TVW4xfbz3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/train.py\", line 286, in <module>\n",
            "    train()\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/train.py\", line 181, in train\n",
            "    raise ValueError(f\"{env_id} not found in gym registry, you maybe meant {closest_match}?\")\n",
            "ValueError: SpaceInvadersNoFrameskip-v4 not found in gym registry, you maybe meant 'no close match found...'?\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeChoX-3SZfP"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuocgdokSab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "========== SpaceInvadersNoFrameskip-v4 ==========\n",
            "Seed: 3866445677\n",
            "Loading hyperparameters from: dqn.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('batch_size', 32),\n",
            "             ('buffer_size', 100000),\n",
            "             ('env_wrapper',\n",
            "              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n",
            "             ('exploration_final_eps', 0.01),\n",
            "             ('exploration_fraction', 0.1),\n",
            "             ('frame_stack', 4),\n",
            "             ('gradient_steps', 1),\n",
            "             ('learning_rate', 0.0001),\n",
            "             ('learning_starts', 100000),\n",
            "             ('n_timesteps', 1000000.0),\n",
            "             ('optimize_memory_usage', False),\n",
            "             ('policy', 'CnnPolicy'),\n",
            "             ('target_update_interval', 1000),\n",
            "             ('train_freq', 4)])\n",
            "Using 1 environments\n",
            "Creating test environment\n",
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Using cuda device\n",
            "Log path: logs//dqn/SpaceInvadersNoFrameskip-v4_2\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.18e+03 |\n",
            "|    ep_rew_mean      | 100      |\n",
            "|    exploration_rate | 0.996    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 1004     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 438      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55e+03 |\n",
            "|    ep_rew_mean      | 110      |\n",
            "|    exploration_rate | 0.987    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 1178     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1294     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.04e+03 |\n",
            "|    ep_rew_mean      | 164      |\n",
            "|    exploration_rate | 0.98     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 1234     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1997     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.98e+03 |\n",
            "|    ep_rew_mean      | 150      |\n",
            "|    exploration_rate | 0.975    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1256     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2494     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.96e+03 |\n",
            "|    ep_rew_mean      | 145      |\n",
            "|    exploration_rate | 0.965    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1287     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3520     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.02e+03 |\n",
            "|    ep_rew_mean      | 155      |\n",
            "|    exploration_rate | 0.961    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1290     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 3946     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.98e+03 |\n",
            "|    ep_rew_mean      | 143      |\n",
            "|    exploration_rate | 0.955    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1298     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4514     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.94e+03 |\n",
            "|    ep_rew_mean      | 142      |\n",
            "|    exploration_rate | 0.951    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1302     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4947     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.97e+03 |\n",
            "|    ep_rew_mean      | 172      |\n",
            "|    exploration_rate | 0.943    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1309     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5770     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2e+03    |\n",
            "|    ep_rew_mean      | 172      |\n",
            "|    exploration_rate | 0.936    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1315     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 6508     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.05e+03 |\n",
            "|    ep_rew_mean      | 174      |\n",
            "|    exploration_rate | 0.928    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1319     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 7237     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.02e+03 |\n",
            "|    ep_rew_mean      | 164      |\n",
            "|    exploration_rate | 0.922    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1321     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 7900     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.03e+03 |\n",
            "|    ep_rew_mean      | 163      |\n",
            "|    exploration_rate | 0.915    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1325     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 8631     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.04e+03 |\n",
            "|    ep_rew_mean      | 162      |\n",
            "|    exploration_rate | 0.908    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1327     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 9311     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.11e+03 |\n",
            "|    ep_rew_mean      | 170      |\n",
            "|    exploration_rate | 0.898    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1330     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 10321    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.07e+03 |\n",
            "|    ep_rew_mean      | 165      |\n",
            "|    exploration_rate | 0.894    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1330     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 10739    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.05e+03 |\n",
            "|    ep_rew_mean      | 163      |\n",
            "|    exploration_rate | 0.886    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1332     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 11486    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.07e+03 |\n",
            "|    ep_rew_mean      | 164      |\n",
            "|    exploration_rate | 0.88     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1332     |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 12119    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.03e+03 |\n",
            "|    ep_rew_mean      | 160      |\n",
            "|    exploration_rate | 0.875    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1333     |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 12601    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.01e+03 |\n",
            "|    ep_rew_mean      | 155      |\n",
            "|    exploration_rate | 0.871    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1333     |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 13018    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.01e+03 |\n",
            "|    ep_rew_mean      | 151      |\n",
            "|    exploration_rate | 0.864    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1334     |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 13781    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2e+03    |\n",
            "|    ep_rew_mean      | 149      |\n",
            "|    exploration_rate | 0.858    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1334     |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 14311    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.97e+03 |\n",
            "|    ep_rew_mean      | 146      |\n",
            "|    exploration_rate | 0.854    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1334     |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 14737    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.95e+03 |\n",
            "|    ep_rew_mean      | 140      |\n",
            "|    exploration_rate | 0.849    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1333     |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 15237    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.97e+03 |\n",
            "|    ep_rew_mean      | 146      |\n",
            "|    exploration_rate | 0.841    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1335     |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 16104    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.02e+03 |\n",
            "|    ep_rew_mean      | 149      |\n",
            "|    exploration_rate | 0.83     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1338     |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 17160    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2e+03    |\n",
            "|    ep_rew_mean      | 153      |\n",
            "|    exploration_rate | 0.826    |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1337     |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 17539    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.99e+03 |\n",
            "|    ep_rew_mean      | 153      |\n",
            "|    exploration_rate | 0.82     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1338     |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 18135    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.97e+03 |\n",
            "|    ep_rew_mean      | 150      |\n",
            "|    exploration_rate | 0.817    |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1338     |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 18504    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.97e+03 |\n",
            "|    ep_rew_mean      | 156      |\n",
            "|    exploration_rate | 0.809    |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1339     |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 19274    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.01e+03 |\n",
            "|    ep_rew_mean      | 160      |\n",
            "|    exploration_rate | 0.798    |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1341     |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 20438    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.02e+03 |\n",
            "|    ep_rew_mean      | 160      |\n",
            "|    exploration_rate | 0.793    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1341     |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 20949    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2e+03    |\n",
            "|    ep_rew_mean      | 155      |\n",
            "|    exploration_rate | 0.787    |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 1341     |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 21478    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2e+03    |\n",
            "|    ep_rew_mean      | 155      |\n",
            "|    exploration_rate | 0.781    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 1342     |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 22133    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.99e+03 |\n",
            "|    ep_rew_mean      | 153      |\n",
            "|    exploration_rate | 0.776    |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 1342     |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 22674    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.99e+03 |\n",
            "|    ep_rew_mean      | 153      |\n",
            "|    exploration_rate | 0.769    |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 1342     |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 23290    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2e+03    |\n",
            "|    ep_rew_mean      | 156      |\n",
            "|    exploration_rate | 0.761    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 1343     |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 24098    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2e+03    |\n",
            "|    ep_rew_mean      | 155      |\n",
            "|    exploration_rate | 0.754    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 1343     |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 24857    |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dLomIiMKQaf"
      },
      "source": [
        "## Let's evaluate our agent üëÄ\n",
        "- RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent. In most RL libraries, we call the evaluation script `enjoy.py`.\n",
        "- Let's evaluate it for 5000 timesteps üî•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co5um_KeKbBJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "usage: enjoy.py [-h] [--env ENV] [-f FOLDER]\n",
            "                [--algo {a2c,ddpg,dqn,ppo,sac,td3,ars,crossq,qrdqn,tqc,trpo,ppo_lstm}]\n",
            "                [-n N_TIMESTEPS] [--num-threads NUM_THREADS] [--n-envs N_ENVS]\n",
            "                [--exp-id EXP_ID] [--verbose VERBOSE] [--no-render]\n",
            "                [--deterministic] [--device DEVICE] [--load-best]\n",
            "                [--load-checkpoint LOAD_CHECKPOINT] [--load-last-checkpoint]\n",
            "                [--stochastic] [--norm-reward] [--seed SEED]\n",
            "                [--reward-log REWARD_LOG]\n",
            "                [--gym-packages GYM_PACKAGES [GYM_PACKAGES ...]]\n",
            "                [--env-kwargs ENV_KWARGS [ENV_KWARGS ...]] [--custom-objects]\n",
            "                [-P]\n",
            "enjoy.py: error: argument -n/--n-timesteps: invalid int value: '_________'\n"
          ]
        }
      ],
      "source": [
        "# !python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps _________  --folder logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q24K1tyWSj7t"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_uSmwGRSk0z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "Loading latest experiment, id=1\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/enjoy.py\", line 288, in <module>\n",
            "    enjoy()\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/enjoy.py\", line 100, in enjoy\n",
            "    raise e\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/enjoy.py\", line 87, in enjoy\n",
            "    _, model_path, log_path = get_model_path(\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/utils.py\", line 518, in get_model_path\n",
            "    raise ValueError(f\"No model found for {algo} on {env_name}, path: {model_path}\")\n",
            "ValueError: No model found for dqn on SpaceInvadersNoFrameskip-v4, path: logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liBeTltiHJtr"
      },
      "source": [
        "## Publish our trained model on the Hub üöÄ\n",
        "Now that we saw we got good results after the training, we can publish our trained model on the hub ü§ó with one line of code.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/space-invaders-model.gif\" alt=\"Space Invaders model\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezbHS1q3HYVV"
      },
      "source": [
        "By using `rl_zoo3.push_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the hub**.\n",
        "\n",
        "This way:\n",
        "- You can **showcase our work** üî•\n",
        "- You can **visualize your agent playing** üëÄ\n",
        "- You can **share with the community an agent that others can use** üíæ\n",
        "- You can **access a leaderboard üèÜ to see how well your agent is performing compared to your classmates** üëâ  https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMSeZRBiHk6X"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n",
        "\n",
        "2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O6FI0F8HnzE"
      },
      "source": [
        "- Copy the token\n",
        "- Run the cell below and past the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppu9yePwHrZX"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b37ea2daaaab4f2ea6d513a5fc5249b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RVEdunPHs8B"
      },
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSLwdmvhHvjw"
      },
      "source": [
        "3Ô∏è‚É£ We're now ready to push our trained agent to the ü§ó Hub üî•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW436XnhHw1H"
      },
      "source": [
        "Let's run push_to_hub.py file to upload our trained agent to the Hub.\n",
        "\n",
        "`--repo-name `: The name of the repo\n",
        "\n",
        "`-orga`: Your Hugging Face username\n",
        "\n",
        "`-f`: Where the trained model folder is (in our case `logs`)\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/select-id.png\" alt=\"Select Id\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygk2sEktTDEw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "Loading latest experiment, id=1\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/push_to_hub.py\", line 324, in <module>\n",
            "    _, model_path, log_path = get_model_path(\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/utils.py\", line 518, in get_model_path\n",
            "    raise ValueError(f\"No model found for {algo} on {env_name}, path: {model_path}\")\n",
            "ValueError: No model found for dqn on SpaceInvadersNoFrameskip-v4, path: logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name _____________________ -orga _____________________ -f logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otgpa0rhS9wR"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HQNlAXuEhci"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "Loading latest experiment, id=1\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/push_to_hub.py\", line 324, in <module>\n",
            "    _, model_path, log_path = get_model_path(\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/utils.py\", line 518, in get_model_path\n",
            "    raise ValueError(f\"No model found for {algo} on {env_name}, path: {model_path}\")\n",
            "ValueError: No model found for dqn on SpaceInvadersNoFrameskip-v4, path: logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name dqn-SpaceInvadersNoFrameskip-v4  -orga ThomasSimonini  -f logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4F5zsTTJ-L"
      },
      "source": [
        "###."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff89kd2HL1_s"
      },
      "source": [
        "Congrats ü•≥ you've just trained and uploaded your first Deep Q-Learning agent using RL-Baselines-3 Zoo. The script above should have displayed a link to a model repository such as https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4. When you go to this link, you can:\n",
        "\n",
        "- See a **video preview of your agent** at the right.\n",
        "- Click \"Files and versions\" to see all the files in the repository.\n",
        "- Click \"Use in stable-baselines3\" to get a code snippet that shows how to load the model.\n",
        "- A model card (`README.md` file) which gives a description of the model and the hyperparameters you used.\n",
        "\n",
        "Under the hood, the Hub uses git-based repositories (don't worry if you don't know what git is), which means you can update the model with new versions as you experiment and improve your agent.\n",
        "\n",
        "**Compare the results of your agents with your classmates** using the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) üèÜ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyRKcCYY-dIo"
      },
      "source": [
        "## Load a powerful trained model üî•\n",
        "- The Stable-Baselines3 team uploaded **more than 150 trained Deep Reinforcement Learning agents on the Hub**.\n",
        "\n",
        "You can find them here: üëâ https://huggingface.co/sb3\n",
        "\n",
        "Some examples:\n",
        "- Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4\n",
        "- Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n",
        "- Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4\n",
        "- Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4\n",
        "\n",
        "Let's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-9QVFIROI5Y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZQNY_r6NJtC"
      },
      "source": [
        "1. We download the model using `rl_zoo3.load_from_hub`, and place it in a new folder that we can call `rl_trained`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdBNZHy0NGTR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n",
            "No normalization file\n",
            "Saving to rl_trained/dqn/BeamRiderNoFrameskip-v4_5\n"
          ]
        }
      ],
      "source": [
        "# Download model and save it into the logs/ folder\n",
        "!python -m rl_zoo3.load_from_hub --algo dqn --env BeamRiderNoFrameskip-v4 -orga sb3 -f rl_trained/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFt6hmWsNdBo"
      },
      "source": [
        "2. Let's evaluate if for 5000 timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOxs0rNuN0uS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "Loading latest experiment, id=5\n",
            "Loading rl_trained/dqn/BeamRiderNoFrameskip-v4_5/BeamRiderNoFrameskip-v4.zip\n",
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/enjoy.py\", line 288, in <module>\n",
            "    enjoy()\n",
            "  File \"/home/libing/source/ml/rl/rl-baselines3-zoo/rl_zoo3/enjoy.py\", line 196, in enjoy\n",
            "    model = ALGOS[algo].load(model_path, custom_objects=custom_objects, device=args.device, **kwargs)\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/stable_baselines3/common/base_class.py\", line 681, in load\n",
            "    data, params, pytorch_variables = load_from_zip_file(\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/stable_baselines3/common/save_util.py\", line 434, in load_from_zip_file\n",
            "    data = json_to_data(json_data, custom_objects=custom_objects)\n",
            "  File \"/home/libing/.conda/envs/deep-rl-class/lib/python3.10/site-packages/stable_baselines3/common/save_util.py\", line 165, in json_to_data\n",
            "    deserialized_object = cloudpickle.loads(base64_object)\n",
            "ModuleNotFoundError: No module named 'gym'\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.enjoy --algo dqn --env BeamRiderNoFrameskip-v4 -n 5000  -f rl_trained/ --no-render"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxMDuDfPON57"
      },
      "source": [
        "Why not trying to train your own **Deep Q-Learning Agent playing BeamRiderNoFrameskip-v4? üèÜ.**\n",
        "\n",
        "If you want to try, check https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters **in the model card, you have the hyperparameters of the trained agent.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL_ZtUgpOuY6"
      },
      "source": [
        "But finding hyperparameters can be a daunting task. Fortunately, we'll see in the next Unit, how we can **use Optuna for optimizing the Hyperparameters üî•.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pqaco8W-huW"
      },
      "source": [
        "## Some additional challenges üèÜ\n",
        "The best way to learn **is to try things by your own**!\n",
        "\n",
        "In the [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) you will find your agents. Can you get to the top?\n",
        "\n",
        "Here's a list of environments you can try to train your agent with:\n",
        "- BeamRiderNoFrameskip-v4\n",
        "- BreakoutNoFrameskip-v4\n",
        "- EnduroNoFrameskip-v4\n",
        "- PongNoFrameskip-v4\n",
        "\n",
        "Also, **if you want to learn to implement Deep Q-Learning by yourself**, you definitely should look at CleanRL implementation: https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif\" alt=\"Environments\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paS-XKo4-kmu"
      },
      "source": [
        "________________________________________________________________________\n",
        "Congrats on finishing this chapter!\n",
        "\n",
        "If you‚Äôre still feel confused with all these elements...it's totally normal! **This was the same for me and for all people who studied RL.**\n",
        "\n",
        "Take time to really **grasp the material before continuing and try the additional challenges**. It‚Äôs important to master these elements and having a solid foundations.\n",
        "\n",
        "In the next unit, **we‚Äôre going to learn about [Optuna](https://optuna.org/)**. One of the most critical task in Deep Reinforcement Learning is to find a good set of training hyperparameters. And Optuna is a library that helps you to automate the search.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WRx7tO7-mvC"
      },
      "source": [
        "\n",
        "\n",
        "### This is a course built with you üë∑üèø‚Äç‚ôÄÔ∏è\n",
        "\n",
        "Finally, we want to improve and update the course iteratively with your feedback. If you have some, please fill this form üëâ https://forms.gle/3HgA7bEHwAmmLfwh9\n",
        "\n",
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc3udPT-RcXc"
      },
      "source": [
        "See you on Bonus unit 2! üî•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS3Xerx0fIMV"
      },
      "source": [
        "### Keep Learning, Stay Awesome ü§ó"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "deep-rl-class",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
